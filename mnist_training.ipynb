{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classification with the MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project was created to study *deep learning* and their concepts. The principal ideia is to build a simple neural network to perform image classification on **[MNIST handwritten digits dataset](http://yann.lecun.com/exdb/mnist/)**. The **[Keras API](https://keras.io/)** is used to load the MNIST dataset and prepare it for training.\n",
    "\n",
    "> MNIST is an acronym that stands for the *Modified National Institute of Standards and Technology*.\n",
    "\n",
    "First of all, its necessary to know the difference between *traditional programming* and *machine learning*.\n",
    "\n",
    "In traditional programming, the programmer is able to articulate rules and conditions in their code that their program can then use to act in the correct way. This approach continues to work exceptionally well for a huge variety of problems.\n",
    "\n",
    "Image classification, which asks a program to correctly classify an image it has never seen before into its correct class, is near impossible to solve with traditional programming techniques. Because of this, *deep learning* became a better solution to this. By training a deep neural network with sufficient data, and providing the network with feedback on its performance via training, the network can identify, though a huge amount of iteration, its own set of conditions by which it can act in the correct way.\n",
    "\n",
    "*Hello World in Deep Learning* - Today, doing image classification with MNIST has become a king of \"Hello World\" for deep learning. Its a collection of 70000 grayscale images of handwriteen digits from 0 to 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation Data and Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with images for deep learning, we need both the images themselves, usually denoted as `X`, and also, correct *labels* for these images, usually denoted as `Y`. Furthermore, we need `X` and `Y` values both for *training* the model, and then, a separate set of `X` and `Y` values for *validating* the performance of the model after it has been trained.\n",
    "\n",
    "1. `x_train`: Images used for training the neural network.\n",
    "2. `y_train`: Correct labels for the `x_train` images, used to evaluate the models predictions during training.\n",
    "3. `x_valid`: Images set aside for validating the performance of the model after it has been trained.\n",
    "4. `y_valid`: Correct labels for the `x_valid` images, used to evaluate the models predictions after it has been trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data Into Memory with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previously mentioned, we will use **Keras framework** to load MNIST dataset and associate to variables.\n",
    "\n",
    "First, we need to import the *MNIST module* like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After import the `mnist` module, we can load the MNIST data and assign to variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_valid, y_valid) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In MNIST dataset, there are 70,000 grayscale images of handwriteen digits. But, we can see that Keras has partitioned 60,000 of these images for training, and 10,000 for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each number is represented by a matrix with *28 columns and 28 rows* with unsigned 8-bit integer values between 0 and 255, the values corresponding with a pixel's grayscale value where `0` is black, `255` is white, and all other values are in between:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.d_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using **[Matplotlib](https://matplotlib.org/)**, we can render one of these grayscale images in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # importing matplotlib module\n",
    "\n",
    "image = x_train[0] # associating the first number in a variable\n",
    "plt.imshow(image, cmap='gray') # using plt.imshow function to show a number in gray scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer is in the `y_train` data, which contains correct labels for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_image = x_train[10]\n",
    "plt.imshow(another_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Data for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In deep learning, it is commom that data needs to be transformed to be in the ideal state for training. For this particular image classification problem, there are 3 tasks we should perform with the data in preparation for training:\n",
    "\n",
    "1. Flatten the image data, to simplify the image input into the model\n",
    "2. Normalize the image data, to make the image input values easier to work with for the model\n",
    "3. Categorize the labels, to make the label values easier to work with for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flattenning the Image Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though it is possible for a deep learning model to accept a 2-dimensional image, we are going to simplify things to start and reshape each image into a single array of `784` (28 * 28) continuous pixels. This is also called **flattening the image**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000, 784)\n",
    "x_valid = x_valid.reshape(10000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the Image Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deep learning models are better at dealing with floating point numbers between 0 and 1**. Converting integer values to floating point values between 0 and 1 is called **[normalization](https://developers.google.com/machine-learning/glossary#normalization)**, and a simple approach we will take here to normalize the data will be to divide all the pixel values by 255:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255\n",
    "x_valid = x_valid / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, all the values in `x_train` and `x_valid` are between `0.0` and `1.0`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this image classification problem, we want it to select the correct category, and understand that if we have an image of the number 5, that guessing 4 is just as bad as guessing 9.\n",
    "\n",
    "The labels for the images are integers between 0 and 9. Because these values represent a numerical range, the model might try to draw some conclusions about its performance based on how close to the correct numerical category it guesses.\n",
    "\n",
    "To resolve this, we will do something to our data called **categorical encoding**. This kind of transformation modifies the data so that each value is a collection of all possible categories, with the actual category that this particular value is set as true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Keras** provides a utility to [categorically encode values](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical), and here we use it perform categorical encoding for both the training and validation labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "num_categories = 10\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_categories)\n",
    "y_valid = keras.utils.to_categorical(y_valid, num_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data prepared for training, it is now time to create the model that we will train with the data. This first basic model will be made up of several *layers* and will be comprised of 3 main parts:\n",
    "\n",
    "1. An input layer, which will receive data in some expected format\n",
    "2. Several [hidden layers](https://developers.google.com/machine-learning/glossary#hidden-layer), each comprised of many *neurons*. Each [neuron](https://developers.google.com/machine-learning/glossary#neuron) will have the ability to affect the network's guess with its *weights*, which are values that will be updated over many iterations as the network gets feedback on its performance and learns\n",
    "3. An output layer, which will depict the network's guess for a given image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, we will use Keras's [Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) model class to instantiate an instance of a model that will have a series of layers that data will pass through in sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Input Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will add the input layer. This layer will be *densely connected*, meaning that each neuron in it, and its weights, will affect every neuron in the next layer. To do this with Keras, we use Keras's [Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) layer class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `units` argument specifies the number of neurons in the layer. Choosing the correct number of neurons is what puts the \"science\" in \"data science\" as it is a matter of capturing the statistical complexity of the dataset.\n",
    "\n",
    "The `activation` argument specifies the activation function to use. If you don't specify anything, no activation is applied.\n",
    "\n",
    "The `input_shape` value specifies the shape of the incoming data which in our situation is a 1D array of 784 values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=512, activation='relu', input_shape=(784,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Hidden Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will add an additional densely connected layer. These layers give the network more parameters to contribute towards its guesses, and therefore, more subtle opportunities for accurate learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units = 512, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Output Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will add an output layer. This layer uses the activation function `softmax` which will result in each of the layer's values being a probability between 0 and 1 and will result in all the outputs of the layer adding to 1. In this case, since the network is to make a guess about a single image belonging to 1 of 10 possible categories, there will be 10 outputs. Each output gives the model's guess (a probability) that the image belongs to that specific class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units = 10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarizing the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras provides the model instance method [summary](https://www.tensorflow.org/api_docs/python/tf/summary) which will print a readable summary of a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the number of trainable parameters. Each of these can be adjusted during training and will contribute towards the trained model's guesses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have prepared training and validation data, and a model, it's time to train our model with our training data, and verify it with its validation data.\n",
    "\n",
    "\"Training a model with data\" is often also called \"fitting a model to data.\" Put this latter way, it highlights that the shape of the model changes over time to more accurately understand the data that it is being given.\n",
    "\n",
    "When fitting (training) a model with Keras, we use the model's [fit](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit) method. It expects the following arguments:\n",
    "\n",
    "* The training data\n",
    "* The labels for the training data\n",
    "* The number of times it should train on the entire training dataset (called an *epoch*)\n",
    "* The validation or test data, and its labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train, epochs=10, verbose=1, validation_data=(x_valid, y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observing Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model did quite well! The accuracy quickly reached close to 100%, as did the validation accuracy. We now have a model that can be used to accurately detect and classify hand-written images.\n",
    "\n",
    "The next step would be to use this model to classify new not-yet-seen handwritten images. This is called [inference](https://blogs.nvidia.com/blog/2016/08/22/difference-deep-learning-training-inference-ai/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's worth taking a moment to appreciate what we've done here. Historically, the expert systems that were built to do this kind of task were extremely complicated, and people spent their careers building them (check out the references on the [official MNIST page](http://yann.lecun.com/exdb/mnist/) and the years milestones were reached).\n",
    "\n",
    "MNIST is not only useful for its historical influence on Computer Vision, but it's also a great [benchmark](http://www.cs.toronto.edu/~serailhydra/publications/tbd-iiswc18.pdf) and debugging tool. Having trouble getting a fancy new machine learning architecture working? Check it against MNIST. If it can't learn on this dataset, chances are it won't learn on more complicated images and datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clear the Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on, please execute the following cell to clear up the GPU memory. This is required to move on to the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ☆ Bonus Exercise ☆\n",
    "\n",
    "Ultimately, each neuron is trying to fit a line to some data. Below, we have some datapoints and a randomly drawn line using the equation [$y = mx + b$](https://www.mathsisfun.com/equation_of_line.html).\n",
    "\n",
    "We have to use `polyfit` function to assign `m` and the `b` in order to find the lowest possible loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 14.87878787878788\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data\n",
    "x = np.array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9])\n",
    "y = np.array([10, 20, 25, 30, 40, 45, 40, 50, 60, 55])\n",
    "\n",
    "mean_squared_error = polyfit(x, y, 1)\n",
    "b = mean_squared_error[0]\n",
    "m = mean_squared_error[1]\n",
    "\n",
    "y_hat = x * m + b\n",
    "\n",
    "plt.plot(x, y, '.')\n",
    "plt.plot(x, y_hat, '-')\n",
    "plt.show()\n",
    "\n",
    "print(\"Loss:\", np.sum((y - y_hat) ** 2) / len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5811388300841898\n"
     ]
    }
   ],
   "source": [
    "data = [(1, 3), (2, 5)]\n",
    "m = -1\n",
    "b = 5\n",
    "\n",
    "def get_rmse(data: list, m: int, b: int):\n",
    "  \"\"\"Calculates Mean Square Error.\"\"\"\n",
    "  n = len(data)\n",
    "  squared_error = 0\n",
    "  for x, y in data:\n",
    "    y_hat = m * x + b\n",
    "    squared_error += (y - y_hat) ** 2\n",
    "  mse = squared_error / n\n",
    "\n",
    "  return mse ** .5\n",
    "\n",
    "print(get_rmse(data, m, b))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c684a6fc7ea5d844d0888e3fc402a914f9a0757a714c6fe2ccce21fe8443d9ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
